---
title: "2331122_Assessment"
author: "Ruchitha"
date: "`r Sys.Date()`"
output: html_document
---

#Section 1: Data inspection and handling missing data:
```{r}
#loading required libraries
library(gtsummary)
library(VIM)
library(mice)
library(ggplot2)
library(naniar)
library(survival)
library(survminer)
library(gplots) #loading the gplots package for heatmap.2 function
library(dplyr)
library(tidyverse)
library(knitr)
library(gridExtra)
library(timeROC)
library(kableExtra)
```

```{r}
#loading the data
bcs <- readRDS("assessment.rds")
head(bcs)
```


```{r}
#summarizing the data and inspecting the data for missing values
summary(bcs)
```

```{r}
#representing missing values into more understandable format
library(gtsummary)
library(knitr)

# create summary table
bcs_tbl <- bcs %>% 
  tbl_summary(missing = "ifany", missing_text = "Missing")

# modify caption
bcs_tbl <- bcs_tbl %>% modify_caption("Table 1: Summary of Breast Cancer Data")

# convert to kable format
bcs_tbl_kable <- bcs_tbl %>% 
  as_kable_extra()

# print table using knitr::knit_print()
bcs_table <- knit_print(bcs_tbl_kable, caption = "Table 1: Summary of Breast Cancer Data")
bcs_table
```

```{r missingness-plot, echo=TRUE, message=FALSE}
cat("### Exploring the Patterns of Missing Data\n\n")

#exploring the patterns of missing data
missingnessplot <- aggr(bcs[, c("hormon", "age", "menostatus", "tsize", "tgrade", "posnodes","progrec", "estrec", "rectime", "recyear", "censrec")],
                    prop = FALSE, numbers = TRUE, sortCombs = TRUE,
                    cex.axis = 0.75, cex.numbers = 0.75)
summary(missingnessplot)
```
The output shows 8 different combinations of missing data across the 11 variables in the dataset. The first column of the output indicates the pattern of missing data, where "0" indicates non-missing data and "1" indicates missing data. The second column shows the count of observations that have this particular combination of missing data. The third column shows the percentage of observations that have this particular combination of missing data.

Based on this output, it appears that the "hormon" variable has 296 missing values, the "age" variable has 375 missing values, and the "rectime" and "recyear" variables have 98 missing values each. On the other hand, the variables "menostatus", "tsize", "tgrade", "posnodes", "progrec", and "estrec" have no missing data.

This information is useful for understanding the completeness of the dataset and identifying variables that may need to be handled or imputed to avoid bias or loss of information in any analysis or modeling. In particular, the large number of missing values for the "age", "hormon", "rectime", and "recyear" variables may warrant additional attention in any data preprocessing or imputation steps.

#finding the missing mechanism of the data
#(i) finding if the missing proportion is MCAR or not
```{r}
#finding if the missingness proportion is MCAR or not

# Create a data frame with missingness information
missing_df <- data.frame(
  var_names = names(bcs),
  missing_prop = colMeans(is.na(bcs))
)

# Create a missing data plot
missing_plot <- ggplot(missing_df, aes(x = reorder(var_names, -missing_prop), y = missing_prop)) +
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  coord_flip() +
  labs(x = "", y = "Proportion missing") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 8))
  
# Overlay the missing data plot of variables of interest with other variables
vars_of_interest <- c("var1", "var2", "var3")
other_vars <- setdiff(names(bcs), vars_of_interest)

missing_plot +
  geom_bar(data = missing_df[missing_df$var_names %in% vars_of_interest,], stat = "identity", fill = "blue", color = "black") +
  geom_bar(data = missing_df[missing_df$var_names %in% other_vars,], stat = "identity", fill = "red", color = "black")

```
The missing proportions plot is a graphical representation of the proportion of missing values in each variable. If the missingness proportion is the same for all observations regardless of the values of other variables, then the missingness is considered to be Missing Completely At Random (MCAR).

To examine if the missingness is MCAR, one can visually inspect the missing proportions plot. If the missingness pattern is random and there are no systematic differences in the proportion of missingness across different subsets of data, then it is likely that the data is MCAR. However, if there are systematic differences in the missingness pattern across different subsets of data, then it suggests that the data is not MCAR.

#perform a correlation analysis between missing indicators and observed variables
```{r}
# Create a dataframe with missingness indicators
missing_indicators <- as.data.frame(sapply(bcs, function(x) ifelse(is.na(x), 1, 0)))
names(missing_indicators) <- paste0("missing_", names(missing_indicators))

# Combine the original dataset with missingness indicators
combined_data <- cbind(bcs, missing_indicators)

# Calculate the correlation matrix for the combined dataset
combined_correlations <- cor(combined_data, use = "pairwise.complete.obs")

# Set a threshold for significant correlations
threshold <- 0.3

# Identify significant correlations and store them in a table
significant_correlations <- which(abs(combined_correlations) > threshold & !is.na(combined_correlations), arr.ind = TRUE)

# Filter out upper triangle of significant correlation matrix
significant_correlations <- significant_correlations[significant_correlations[,1] >= significant_correlations[,2],]

# Create data frame of significant correlations
table_rows <- data.frame(row_name = rownames(combined_correlations)[significant_correlations[,1]],
                          col_name = colnames(combined_correlations)[significant_correlations[,2]],
                          correlation = combined_correlations[significant_correlations])

# Remove redundant values
table_rows <- table_rows[!duplicated(paste(pmin(table_rows$row_name, table_rows$col_name),
                                             pmax(table_rows$row_name, table_rows$col_name))),]

# Print the table of significant correlations
significant_table <- knitr::kable(table_rows, 
             caption = "Table-2:Significant Correlations (threshold = 0.3)",
             align = "c") %>%
  kableExtra::kable_styling(bootstrap_options = "striped",
                            full_width = FALSE)

significant_table

# Generate the heatmap
heatmap(combined_correlations, 
        Rowv = NA, Colv = NA, 
        col = colorRampPalette(c("blue", "white", "red"))(25), 
        scale = "none", margins = c(10, 10),)

```
The correlation matrix between the combined dataset is computed and plotted as a heatmap, where brighter colors indicate stronger correlations.

In the list of significant correlations, there are various correlations identified between pairs of variables in the dataset, including both observed variables and missingness indicators. The values of the correlations range from -1 to 1, where -1 indicates a perfect negative correlation, 0 indicates no correlation, and 1 indicates a perfect positive correlation.

A correlation of 1 between a variable and itself (e.g., id and id, hormon and hormon, etc.) is expected and indicates that the variable is perfectly correlated with itself.

The correlation between age and menostatus is 0.7717776, indicating a strong positive correlation. This means that as age increases, the probability of menopause increases as well.

The correlation between tsize and posnodes is 0.327665, indicating a moderate positive correlation. This means that as tumor size increases, the number of positive lymph nodes also tends to increase.

The correlation between x5e and posnodes is -0.8966952, indicating a strong negative correlation. This means that as the size of the largest area of extranodal extension decreases, the number of positive lymph nodes tends to increase.

The correlation between tsize and missing_hormon is 0.4927027, indicating a moderate positive correlation. This means that as tumor size increases, the probability of missing hormone receptor status increases as well.

The correlations between missingness indicators (e.g., missing_hormon and missing_hormon, missing_age and missing_age) are all 1, indicating perfect correlation between a variable and itself.

Overall, these significant correlations help to identify relationships between variables in the dataset and can inform further analyses and modeling.

The significant correlations in the output can be interpreted as follows:

Strong correlation: A correlation coefficient of 0.8 or above indicates a strong positive correlation, such as the correlation between age and menostatus with a coefficient of 0.7717776.
Moderate correlation: A correlation coefficient between 0.5 and 0.8 indicates a moderate positive correlation, such as the correlation between tsize and missing_hormon with a coefficient of 0.4927027.
Weak correlation: A correlation coefficient between 0.3 and 0.5 indicates a weak positive correlation, such as the correlation between posnodes and tsize with a coefficient of 0.327665.
No correlation: A correlation coefficient close to 0 indicates no linear relationship between the variables, such as the correlation between id and id with a coefficient of 1.
Note that a strong negative correlation would have a correlation coefficient of -0.8 or below, a moderate negative correlation would have a correlation coefficient between -0.5 and -0.8, and a weak negative correlation would have a correlation coefficient between -0.3 and -0.5.

based on the significant correlations listed, the variables with significant positive correlations are:
menostatus and age
x4a and tgrade
x4b and tgrade
These variables have correlation coefficients greater than the specified threshold of 0.3 and are positively correlated, which means that when one variable increases, the other variable also tends to increase.

Since the missingness indicators are significantly correlated with some of the observed variables, this suggests that the missing data mechanism may not be missing completely at random (MCAR). Instead, it is likely that the data is missing at random (MAR), which means that the probability of missing data is related to the observed data, but not to the missing data itself. This has implications for the types of methods that can be used to handle missing data in subsequent analyses.

```{r}
#finding the correlation between rectime and recyear
cor(bcs$rectime, bcs$recyear, use = "complete.obs")
```
since the correlation between two variables is 1, it means that they are perfectly correlated, and there is no variability in their relationship. In this case, it does not matter which variable is used in the analysis as they are interchangeable and provide the same information. Therefore, you can use any one of the variables for further analysis, and it would not affect the results. However, it is always good practice to use the most appropriate variable depending on the research question and context.

In the given context, it would be more suitable to use rectime (recurrence free survival in days) as the outcome variable for the prognostic time to event model. This is because rectime provides a more precise measure of the time to recurrence compared to recyear (recurrence free survival in years), which only provides an estimate of the time to recurrence. Since the study aims to fit a prognostic time to event model, using the more precise measure of time to recurrence would be more appropriate. Additionally, using rectime as the outcome variable would allow for more flexibility in the choice of time scale and the inclusion of time-dependent covariates in the model.

#using multiple imputation for handling missing data
```{r}
imputed_bcs <- mice(bcs, m = 5, maxit = 50)
#since recyear and rectime are strongly correlated, we divide rectime by 365.25 to convert it from days to years and impute into the dataset
imputed_bcs$imp$recyear <- imputed_bcs$imp$rectime / 365.25
imputed_bcs <- complete(imputed_bcs)
```
Multiple imputation is a widely used method for handling missing data when the missing data mechanism is missing at random (MAR). When data are MAR, the probability of missingness depends on the observed data but not on the unobserved (missing) data. In other words, the missingness is systematically related to the observed data but not to the missing data. In such cases, multiple imputation can be a useful method for addressing missing data because it allows for the incorporation of information from the observed data to estimate plausible values for the missing data.

One of the key advantages of multiple imputation is that it accounts for the uncertainty associated with the missing data. Multiple imputation involves creating multiple imputed datasets, each of which includes plausible values for the missing data. These datasets are then analyzed separately using the same statistical model, and the results are combined using established rules that account for the variability between the imputed datasets. This approach results in valid statistical inference that reflects the uncertainty associated with the missing data.

In contrast to other missing data handling techniques such as listwise deletion or single imputation, multiple imputation does not result in a loss of information or statistical power, and can provide unbiased estimates of population parameters under MAR. Additionally, multiple imputation can handle missing data in both categorical and continuous variables, and can be used with a variety of statistical models, including regression, survival analysis, and clustering.

Therefore, based on the finding that the missing mechanism is MAR, using multiple imputation can be a valid and effective method for handling the missing data and obtaining valid statistical inferences from the data.

This code uses the mice function from the mice package in R to perform multiple imputation on the dataset bcs.

The mice function takes several arguments, including:

data: the dataset to be imputed
m: the number of imputed datasets to create
maxit: the maximum number of iterations to use when imputing the data
In this case, the code specifies m = 5, which means that five imputed datasets will be created. It also specifies maxit = 50, which means that up to 50 iterations will be used to impute the data.

The output of the mice function is an object of class mids, which contains the imputed datasets as well as other information about the imputation process. The imputed datasets can be accessed using the complete function, which returns a single imputed dataset based on a specified imputation number. For example, complete(imputed_bcs, 1) returns the first imputed dataset, while complete(imputed_bcs, 2) returns the second imputed dataset.

Overall, this code performs multiple imputation on the bcs dataset using the mice function with five imputed datasets and a maximum of 50 iterations, and saves the output as an mids object called imputed_bcs.

```{r}
#checking if there are any missing values in the imputed data set
sum(is.na(imputed_bcs))
```

#Section-2: Covariate Selection
Performing exploratory data analysis (e.g., Kaplan-Meier curves, log-rank tests) to identify potential associations between the covariates and recurrence-free survival.

#For each covariate, we can create a Kaplan-Meier curve to visualize the association between that variable and recurrence-free survival.
```{r}
imputed_bcs_cat <- imputed_bcs
# Categorize continuous variables into quartiles for more readable format of the curves
imputed_bcs_cat$age_group <- cut(imputed_bcs_cat$age, 
                               breaks = c(25, 40, 55, Inf), 
                               include.lowest = TRUE, 
                               labels = c( "25-40", "41-55", "56 and older"))
imputed_bcs_cat$tsize_group <- cut(imputed_bcs_cat$tsize, 
                                 breaks = c(0, 30, 60, 90, 120), 
                                 include.lowest = TRUE, 
                                 labels = c("0-30", "31-60", "61-90", "91 and larger"))
imputed_bcs_cat$posnodes_group <- cut(imputed_bcs_cat$posnodes, 
                                   breaks = c(0, 15, 25, 35, Inf), 
                                   include.lowest = TRUE, 
                                   labels = c("0-15", "16-25", "26-35", "36 and more"))
imputed_bcs_cat$progrec_group <- cut(imputed_bcs_cat$progrec, 
                                  breaks = c(0, 600, 1200, 1800, Inf), 
                                  include.lowest = TRUE, 
                                  labels = c("0-600", "601-1200", "1201-1800", "1800 and larger"))
imputed_bcs_cat$estrec_group <- cut(imputed_bcs_cat$estrec, 
                                  breaks = c(0, 300, 600, 900, Inf), 
                                  include.lowest = TRUE, 
                                  labels = c("0-300", "301-600", "601-900", "900 and larger"))

# List of categorized covariate names
covariate_names <- c("hormon", "age_group", "menostatus", "tsize_group", "tgrade", "posnodes_group", "progrec_group", "estrec_group")

# Function to create a Kaplan-Meier plot for a specific covariate
create_km_plot <- function(covariate) {
  km_fit <- survfit(Surv(rectime, censrec) ~ imputed_bcs_cat[[covariate]], data = imputed_bcs_cat)
  g <- ggsurvplot(
    km_fit,
    data = imputed_bcs_cat,
    risk.table = TRUE,
    risk.table.height = 0.5,
    pval = TRUE,
    xlab = "Time",
    ylab = "Survival Probability",
    title = paste("Kaplan-Meier Curve by", covariate)
  )
  return(g$plot) # Return the ggplot object
}
# Collect the plots in a list
plots <- lapply(covariate_names, create_km_plot)

# Convert the ggplot objects to grobs
plots_grob <- lapply(plots, ggplotGrob)

# Arrange the grobs into a grid using arrangeGrob()
grid_plots <- do.call(gridExtra::arrangeGrob, c(plots_grob, ncol = 2))

# Save the arranged plots to a single png file
png("km_plots.png", width = 16, height = 20, units = "in", res = 300)
grid::grid.newpage()
grid::grid.draw(grid_plots)
dev.off()
```
The output of the Kaplan-Meier curve for the chosen interest variable provides information about the association between interest variable  and recurrence-free survival.

The x-axis represents time, and the y-axis represents the probability of remaining recurrence-free at that time point. The solid line represents the Kaplan-Meier survival estimate for patients with hormone receptor-positive breast cancer, while the dashed line represents the Kaplan-Meier survival estimate for patients with hormone receptor-negative breast cancer.

The plot also includes a table that shows the number of patients at risk, the number of events (i.e., recurrence or death) observed at each time point, and the survival probability estimate and confidence interval for each group.

The p-value in the plot represents the statistical significance of the difference in recurrence-free survival between the two groups. A p-value less than 0.05 indicates that there is a significant difference in recurrence-free survival between the two groups.

Interpret the risk table: The Kaplan-Meier curve may also include a risk table, which shows the number of patients at risk, the number of events (e.g., recurrence or death) observed at each time point, and the survival probability estimate and confidence interval for each group. You can use the risk table to understand the magnitude of the differences in survival between the groups and to identify time points where the differences are most pronounced.

Consider potential confounding factors: It's important to consider other factors that may be associated with both the variable of interest and recurrence-free survival. These factors could confound the relationship between the variable of interest and survival. For example, if age is associated with both hormone receptor status and recurrence-free survival, the observed association between hormone receptor status and survival may be confounded by age. Therefore, it's important to adjust for potential confounding factors in the analysis to obtain a more accurate estimate of the association between the variable of interest and survival.

Overall, the Kaplan-Meier curve provides a visual and statistical tool to investigate the association between a variable and recurrence-free survival. By interpreting the survival curve, looking at the p-value and risk table, and considering potential confounding factors, you can draw meaningful conclusions about the association and guide further research or clinical decision-making.

#To statistically test the association between a covariate and recurrence-free survival, you can perform a log-rank test.
```{r}
#Log-rank test for the hormon variable
logrank_test_hormon <- survdiff(Surv(rectime, censrec) ~ hormon, data = imputed_bcs)
logrank_test_hormon
```
The log-rank test statistic is shown as Chisq= 17.3 with 1 degree of freedom, and the p-value is p= 3e-05, which is very small. This indicates that there is a statistically significant difference in survival experience between the two groups based on the hormon variable. Specifically, the group with hormon=0 has a higher expected survival time than the group with hormon=1.

In summary, the log-rank test result suggests that the hormon variable is a significant predictor of survival in the imputed_bcs dataset.

```{r}
#Log-rank test for the age variable
logrank_test_age <- survdiff(Surv(rectime, censrec) ~ age, data = imputed_bcs)
logrank_test_age
```
The output of the survdiff function provides information about the test results. The log-rank test statistic is shown as Chisq= 106 with 48 degrees of freedom, and the p-value is p= 3e-06, which is very small. This indicates that there is a statistically significant difference in survival experience between the different age groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the age groups is statistically significant. However, it is not possible to determine which specific age groups are different from each other based on this output alone.

In summary, the log-rank test result suggests that the age variable is a significant predictor of survival in the imputed_bcs dataset. However, additional analyses such as pairwise comparisons or modeling may be needed to better understand the relationship between age and survival in this dataset.
```{r}
#Log-rank test for the menostatus variable
logrank_test_menostatus <- survdiff(Surv(rectime, censrec) ~ menostatus, data = imputed_bcs)
logrank_test_menostatus
```
The log-rank test statistic is shown as Chisq= 1.4 with 1 degree of freedom, and the p-value is p= 0.2. This indicates that there is no statistically significant difference in survival experience between the two groups based on the menostatus variable. Specifically, the difference in expected survival time between the two groups is not large enough to be considered statistically significant.

In summary, the log-rank test result suggests that the menostatus variable is not a significant predictor of survival in the imputed_bcs dataset. This means that the menopausal status of breast cancer patients may not be associated with differences in their survival experience.
```{r}
#Log-rank test for the tsize variable
logrank_test_tsize <- survdiff(Surv(rectime, censrec) ~ tsize, data = imputed_bcs)
logrank_test_tsize
```
The log-rank test statistic is shown as Chisq= 130 with 57 degrees of freedom, and the p-value is p= 1e-07, which is very small. This indicates that there is a statistically significant difference in survival experience between the different tumor size groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the tumor size groups is statistically significant. However, it is not possible to determine which specific tumor size groups are different from each other based on this output alone.

In summary, the log-rank test result suggests that the tsize variable is a significant predictor of survival in the imputed_bcs dataset. However, additional analyses such as pairwise comparisons or modeling may be needed to better understand the relationship between tumor size and survival in this dataset.
```{r}
#Log-rank test for the tgrade variable
logrank_test_tgrade <- survdiff(Surv(rectime, censrec) ~ tgrade, data = imputed_bcs)
logrank_test_tgrade
```
The log-rank test statistic is shown as Chisq= 24.9 with 2 degrees of freedom, and the p-value is p= 4e-06, which is very small. This indicates that there is a statistically significant difference in survival experience between the different tumor grade groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the tumor grade groups is statistically significant. From the output, it can be seen that there is a significantly lower survival rate for patients with a tumor grade of 1 (tgrade=1) compared to those with a tumor grade of 2 (tgrade=2) or 3 (tgrade=3).

In summary, the log-rank test result suggests that the tgrade variable is a significant predictor of survival in the imputed_bcs dataset. Specifically, a lower tumor grade is associated with better survival outcomes. However, additional analyses such as modeling may be needed to better understand the relationship between tumor grade and survival in this dataset.
```{r}
#Log-rank test for the posnodes variable
logrank_test_posnodes <- survdiff(Surv(rectime, censrec) ~ posnodes, data = imputed_bcs)
logrank_test_posnodes
```
The log-rank test statistic is shown as Chisq= 209 with 29 degrees of freedom, and the p-value is p= <2e-16, which is very small. This indicates that there is a statistically significant difference in survival experience between the different nodal status groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the nodal status groups is statistically significant. However, it is not possible to determine which specific nodal status groups are different from each other based on this output alone.

In summary, the log-rank test result suggests that the posnodes variable is a significant predictor of survival in the imputed_bcs dataset. However, additional analyses such as pairwise comparisons or modeling may be needed to better understand the relationship between nodal status and survival in this dataset.

```{r}
#Log-rank test for the progrec variable
logrank_test_progrec <- survdiff(Surv(rectime, censrec) ~ progrec, data = imputed_bcs)
logrank_test_progrec
```
The log-rank test statistic is shown as Chisq= 390 with 240 degrees of freedom, and the p-value is p= 3e-09, which is very small. This indicates that there is a statistically significant difference in survival experience between the different progrec groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the progrec groups is statistically significant. However, it is not possible to determine which specific progrec groups are different from each other based on this output alone.

In summary, the log-rank test result suggests that the progrec variable is a significant predictor of survival in the imputed_bcs dataset. However, additional analyses such as pairwise comparisons or modeling may be needed to better understand the relationship between progrec and survival in this dataset.
```{r}
#Log-rank test for the estrec variable
logrank_test_estrec <- survdiff(Surv(rectime, censrec) ~ estrec, data = imputed_bcs)
logrank_test_estrec
```
The log-rank test statistic is shown as Chisq= 391 with 243 degrees of freedom, and the p-value is p= 5e-09, which is very small. This indicates that there is a statistically significant difference in survival experience between the different estrec groups in the imputed_bcs dataset.

Specifically, the p-value suggests that the difference in survival experience between at least two of the estrec groups is statistically significant. However, it is not possible to determine which specific estrec groups are different from each other based on this output alone.

In summary, the log-rank test result suggests that the estrec variable is a significant predictor of survival in the imputed_bcs dataset. However, additional analyses such as pairwise comparisons or modeling may be needed to better understand the relationship between estrec and survival in this dataset.

```{r}
# Create a data frame with variable names and p-values
pvalue_table <- data.frame(variable = c("hormon", "age", "menostatus", "tsize", "tgrade", "posnodes", "progrec", "estrec"), pvalue = c('3e-05', '3e-06', 0.2, '1e-07', '4e-07', '<2e-16', '3e-09', '5e-09'), Chisq = c(17.3, 106, 1.4, 130, 24.9, 209, 390, 391), Df = c(1, 48, 1, 57, 2, 29, 240, 243))

# Print the p-value table using knitr::kable()
pvalue_table <- kable(pvalue_table, caption = "Table 3: Summary of the Log-rank Test", align = "c")

pvalue_table
```
These results are from performing a log-rank test on several variables in the imputed_bcs dataset to evaluate their potential as predictors of survival.

For each variable (hormon, age, menostatus, tsize, tgrade, posnodes, progrec, and estrec), the output includes the p-value, the test statistic (Chisq), and the degrees of freedom (Df).

The p-value represents the probability of observing the test statistic (or a more extreme value) if there is truly no difference in survival between the groups being compared. A smaller p-value indicates stronger evidence against the null hypothesis of no difference in survival.

The Chisq value represents the test statistic for the log-rank test, which measures the overall difference in survival between the groups being compared. A larger Chisq value indicates a larger difference in survival between the groups.

The degrees of freedom represent the number of categories being compared minus one.

Based on these results, hormon, age, tsize, tgrade, posnodes, progrec, and estrec all have very small p-values, indicating strong evidence against the null hypothesis of no difference in survival. This suggests that these variables are significant predictors of survival in the imputed_bcs dataset.

On the other hand, menostatus has a relatively large p-value of 0.2, which suggests weaker evidence against the null hypothesis of no difference in survival. This indicates that menostatus may not be a significant predictor of survival in the imputed_bcs dataset.

Overall, these log-rank test results suggest that hormon, age, tsize, tgrade, posnodes, progrec, and estrec may be important variables to consider in predicting survival in the imputed_bcs dataset.
#justify the covariates you choose to include in your prognostic model:
When building a prognostic model, it is important to select covariates that are clinically relevant and have been shown to be associated with the outcome of interest. In the case of a survival analysis, we want to select covariates that are predictive of survival or time to event.

Based on the results of the log-rank tests, we can see that the variables "age", "tsize", "tgrade", "posnodes", "progrec", and "estrec" have highly significant p-values, indicating that they are strong predictors of survival in this dataset. "menostatus" is not found to be significant predictors of survival in this dataset.

However, it is important to note that statistical significance alone is not sufficient for variable selection. It is also important to consider the clinical relevance of the variables and their potential impact on the outcome. For example, "age" and "tsize" are often considered important predictors of survival in breast cancer, as older patients and those with larger tumors may have a worse prognosis. "Tgrade" is a measure of the aggressiveness of the tumor and can also impact prognosis. "Posnodes", "progrec", and "estrec" are markers of the extent of the cancer and its response to treatment, and are also clinically relevant predictors of survival.


Furthermore, the hormon variable is clinically relevant in breast cancer as it refers to the hormone receptor status of the tumor. Breast cancer tumors can be classified into hormone receptor-positive (estrogen receptor or progesterone receptor positive), hormone receptor-negative (estrogen receptor and progesterone receptor negative), or HER2-positive. Hormone receptor-positive tumors have been shown to have better outcomes and respond well to hormone therapy. Therefore, including the hormon variable in the prognostic model can provide important clinical information for treatment decisions and prognosis.

Therefore, based on both the statistical significance and clinical relevance, I would choose to include "age", "tsize", "tgrade", "posnodes", "progrec", and "estrec" as covariates in my prognostic model for breast cancer survival. However, the final selection of covariates should be based on a careful evaluation of the data, consideration of potential confounding factors, and validation of the model in independent datasets.
#finding the correlation between covariates
```{r}
# Subset the covariates
covariates <- imputed_bcs[, c("hormon", "age", "menostatus", "tsize", "tgrade", "posnodes", "progrec", "estrec")]


# Calculate the correlation matrix
corr_matrix <- cor(covariates)

# Print the correlation matrix
print(corr_matrix)

# Remove missing or infinite values from the correlation matrix
corr_matrix[is.na(corr_matrix)] <- 0 # Replace missing values with 0
corr_matrix <- na.omit(corr_matrix) # Remove rows or columns with missing values

# Visualize the updated correlation matrix with a heatmap
heatmap(corr_matrix, 
        col = colorRampPalette(c("white", "blue"))(100), 
        scale = "none", 
        symm = TRUE)
```
The result shows the correlation matrix between the chosen covariates: hormon, age, menostatus, tsize, tgrade, posnodes, progrec, and estrec. The values range from -1 to 1, where a positive value indicates a positive correlation, a negative value indicates a negative correlation, and a value of 0 indicates no correlation.

Looking at the matrix, we can see that hormon has a weak positive correlation with age (0.26) and menostatus (0.32). Age and menostatus have a strong positive correlation (0.77). Tsize has a weak positive correlation with posnodes (0.33) and a weak negative correlation with estrec (-0.08). Tgrade has a weak negative correlation with hormon (-0.04) and progrec (-0.18) and a weak positive correlation with tsize (0.10). Posnodes has a weak positive correlation with tsize (0.33) and a weak negative correlation with progrec (-0.07) and estrec (-0.04). Progrec has a weak positive correlation with age (0.04) and estrec (0.39) and a weak negative correlation with hormon (-0.06), tgrade (-0.18), and posnodes (-0.07). Finally, estrec has a weak positive correlation with age (0.26), menostatus (0.26), and progrec (0.39) and a weak negative correlation with tsize (-0.08) and tgrade (-0.12).

Overall, the correlation matrix provides insight into the relationships between the covariates and helps identify potential multicollinearity issues that may need to be addressed in the modeling process.

#Section-3: Model Selection:
#fitting a prognostic time-to-event model
```{r}
#Fit the Cox model on each imputed dataset and store the results in a list.
cox_model_list <- lapply(imputed_bcs, function(x) {
  coxph(Surv(rectime, censrec) ~ hormon + age + tsize + tgrade + posnodes + progrec + estrec, data = imputed_bcs)
})

pooled_cox_model <- pool(cox_model_list)
summary(pooled_cox_model)
```
The model aims to investigate the relationship between several independent variables (hormon, age, tsize, tgrade, posnodes, progrec, and estrec) and the survival time of breast cancer patients (rectime, with censoring status given by censrec).
Here is an interpretation of the variables and their results:

hormon: The hazard ratio is exp(-0.568) = 0.567, indicating that patients with hormonal treatment have a 43.3% lower risk of an event (e.g., death) compared to those without hormonal treatment, holding all other variables constant. This effect is statistically significant with a p-value of 7.33e-06.

age: The hazard ratio is exp(0.0037) = 1.0037, suggesting a slight increase in the risk of an event for each additional year of age, but this effect is not statistically significant (p-value = 0.546).

tsize: The hazard ratio is exp(0.0161) = 1.0162, indicating a 1.6% increase in the risk of an event for each additional millimeter of tumor size. This effect is statistically significant (p-value = 1.72e-04).

tgrade: The hazard ratio is exp(0.374) = 1.453, suggesting that for each unit increase in tumor grade, the risk of an event increases by 45.3%, holding all other variables constant. This effect is statistically significant (p-value = 5.49e-04).

posnodes: The hazard ratio is exp(0.0335) = 1.034, indicating a 3.4% increase in the risk of an event for each additional positive lymph node. This effect is statistically significant (p-value = 1.07e-06).

progrec: The hazard ratio is exp(-0.00177) = 0.998, suggesting a slight decrease in the risk of an event for each additional unit of progesterone receptor level, but this effect is statistically significant (p-value = 1.32e-03).

estrec: The hazard ratio is exp(-0.00034) = 0.999, indicating a negligible decrease in the risk of an event for each additional unit of estrogen receptor level. This effect is not statistically significant (p-value = 0.426).

In summary, the variables hormon, tsize, tgrade, posnodes, and progrec show significant associations with the survival time of breast cancer patients, while age and estrec do not have
significant effects on survival time in this Cox proportional hazards model. It is important to consider these results in the context of the study design, sample size, and any assumptions or limitations of the model. Ultimately, this analysis provides insights into the relationships between various factors and the survival time of breast cancer patients, which can inform clinical decision-making, risk stratification, and further research.

```{r}
#Fit the Cox model on each imputed dataset and store the results in a list.
cox_model_list1 <- lapply(imputed_bcs, function(x) {
  coxph(Surv(rectime, censrec) ~ hormon + age + tsize + tgrade + posnodes + progrec, data = imputed_bcs)
})

pooled_cox_model1 <- pool(cox_model_list1)
summary(pooled_cox_model1)
```
Here is an interpretation of the variables and their results:

hormon: The hazard ratio is exp(-0.586) = 0.557, indicating that patients with hormonal treatment have a 44.3% lower risk of an event (e.g., death) compared to those without hormonal treatment, holding all other variables constant. This effect is statistically significant with a p-value of 2.89e-06.

age: The hazard ratio is exp(0.0027) = 1.0027, suggesting a slight increase in the risk of an event for each additional year of age, but this effect is not statistically significant (p-value = 0.651).

tsize: The hazard ratio is exp(0.0167) = 1.0168, indicating a 1.7% increase in the risk of an event for each additional millimeter of tumor size. This effect is statistically significant (p-value = 8.76e-05).

tgrade: The hazard ratio is exp(0.371) = 1.449, suggesting that for each unit increase in tumor grade, the risk of an event increases by 44.9%, holding all other variables constant. This effect is statistically significant (p-value = 6.02e-04).

posnodes: The hazard ratio is exp(0.0328) = 1.033, indicating a 3.3% increase in the risk of an event for each additional positive lymph node. This effect is statistically significant (p-value = 1.41e-06).

progrec: The hazard ratio is exp(-0.00186) = 0.998, suggesting a slight decrease in the risk of an event for each additional unit of progesterone receptor level, and this effect is statistically significant (p-value = 5.82e-04).

In summary, the variables hormon, tsize, tgrade, posnodes, and progrec show significant associations with the survival time of breast cancer patients, while age does not have a significant effect on survival time in this Cox proportional hazards model. Excluding the "estrec" variable from the model does not seem to have a significant impact on the overall results and interpretations. 

```{r}
# Calculate the likelihood ratio test statistic

# Define a function to extract log-likelihood values and calculate the likelihood ratio test statistic
lr_statistic <- function(model1, model2) {
  loglik1 <- model1$loglik[2]
  loglik2 <- model2$loglik[2]
  return(-2 * (loglik2 - loglik1))
}

# Calculate the likelihood ratio test statistic for each imputed dataset
lr_stats_list <- mapply(lr_statistic, cox_model_list, cox_model_list1, SIMPLIFY = TRUE)
# Pool the likelihood ratio test statistics using Rubin's rules
pooled_lr_statistic <- mean(lr_stats_list)
pooled_lr_statistic

# Calculate the p-value
p_value <- pchisq(pooled_lr_statistic, df = 1, lower.tail = FALSE)
p_value
```

The pooled likelihood ratio test statistic is 0.669, and the associated p-value is 0.413. This p-value is greater than the typical significance level of 0.05, which indicates that there is not enough evidence to suggest that the full model (including the estrec variable) provides a significantly better fit to the data compared to the reduced model (without the estrec variable).

In other words, based on this likelihood ratio test, the estrec variable does not contribute significantly to the model's fit, and the reduced model (without the estrec variable) is sufficient for explaining the relationships between the other independent variables and the survival time of breast cancer patients.

```{r}
#Fit the Cox model on each imputed dataset and store the results in a list.
cox_model_list2 <- lapply(imputed_bcs, function(x) {
  coxph(Surv(rectime, censrec) ~ hormon + tsize + tgrade + posnodes + progrec, data = imputed_bcs)
})

pooled_cox_model2 <- pool(cox_model_list2)
summary(pooled_cox_model2)
```
The given result is a summary of the pooled Cox proportional hazards model that has been fit on each imputed dataset, excluding the age and estrec variables. The model investigates the relationships between survival time (rectime) and the independent variables: hormon, tsize, tgrade, posnodes, and progrec. Here's an interpretation of the results:

hormon (hormone therapy): The estimated hazard ratio is -0.580 with a standard error of 0.122. The statistic is -4.75, and the p-value is 3.205e-06. Since the p-value is less than 0.05, there is a significant association between hormone therapy and the survival time of breast cancer patients. A negative estimate indicates that patients who received hormone therapy have a lower hazard of experiencing the event (e.g., death) compared to those who did not receive hormone therapy.

tsize (tumor size): The estimated hazard ratio is 0.017 with a standard error of 0.004. The statistic is 3.979, and the p-value is 8.676e-05. The significant p-value suggests that there is a significant association between tumor size and the survival time of breast cancer patients. A positive estimate indicates that larger tumors are associated with a higher hazard of experiencing the event.

tgrade (tumor grade): The estimated hazard ratio is 0.365 with a standard error of 0.106. The statistic is 3.439, and the p-value is 6.67e-04. With a significant p-value, there is a significant association between tumor grade and survival time. A higher tumor grade is associated with a higher hazard of experiencing the event.

posnodes (number of positive lymph nodes): The estimated hazard ratio is 0.033 with a standard error of 0.0066. The statistic is 5.008, and the p-value is 9.397e-07. This significant p-value indicates a significant association between the number of positive lymph nodes and survival time. A higher number of positive lymph nodes is associated with a higher hazard of experiencing the event.

progrec (progesterone receptor level): The estimated hazard ratio is -0.00187 with a standard error of 0.000536. The statistic is -3.478, and the p-value is 5.795e-04. Since the p-value is less than 0.05, there is a significant association between progesterone receptor level and survival time. A negative estimate indicates that higher progesterone receptor levels are associated with a lower hazard of experiencing the event.

In summary, this analysis indicates that all of the included independent variables are significantly associated with the survival time of breast cancer patients. It is important to consider these results in the context of the study design, sample size, and any assumptions or limitations of the model. This analysis can inform clinical decision-making, risk stratification, and further research.

```{r}
# Calculate the likelihood ratio test statistic

# Define a function to extract log-likelihood values and calculate the likelihood ratio test statistic
lr_statistic <- function(model1, model2) {
  loglik1 <- model1$loglik[2]
  loglik2 <- model2$loglik[2]
  return(-2 * (loglik2 - loglik1))
}

# Calculate the likelihood ratio test statistic for each imputed dataset
lr_stats_list1 <- mapply(lr_statistic, cox_model_list1, cox_model_list2, SIMPLIFY = TRUE)
# Pool the likelihood ratio test statistics using Rubin's rules
pooled_lr_statistic1 <- mean(lr_stats_list1)
pooled_lr_statistic1

# Calculate the p-value
p_value1 <- pchisq(pooled_lr_statistic1, df = 1, lower.tail = FALSE)
p_value1
```
The given result is the pooled likelihood ratio test statistic and associated p-value for comparing two Cox proportional hazards models:

Model 1: Including hormon, age, tsize, tgrade, posnodes, and progrec as independent variables.
Model 2: Including hormon, tsize, tgrade, posnodes, and progrec as independent variables (excluding age).
The pooled likelihood ratio test statistic is 0.206, and the associated p-value is 0.650. This p-value is greater than the typical significance level of 0.05, which indicates that there is not enough evidence to suggest that Model 1 (including the age variable) provides a significantly better fit to the data compared to Model 2 (without the age variable).

In other words, based on this likelihood ratio test, the age variable does not contribute significantly to the model's fit, and Model 2 (without the age variable) is sufficient for explaining the relationships between the other independent variables and the survival time of breast cancer patients.


```{r}
# Calculate the likelihood ratio test statistic

# Define a function to extract log-likelihood values and calculate the likelihood ratio test statistic
lr_statistic <- function(model1, model2) {
  loglik1 <- model1$loglik[2]
  loglik2 <- model2$loglik[2]
  return(-2 * (loglik2 - loglik1))
}

# Calculate the likelihood ratio test statistic for each imputed dataset
lr_stats_list2 <- mapply(lr_statistic, cox_model_list, cox_model_list2, SIMPLIFY = TRUE)
# Pool the likelihood ratio test statistics using Rubin's rules
pooled_lr_statistic2 <- mean(lr_stats_list2)
pooled_lr_statistic2

# Calculate the p-value
p_value2 <- pchisq(pooled_lr_statistic2, df = 1, lower.tail = FALSE)
p_value2
```

The given result is the pooled likelihood ratio test statistic and associated p-value for comparing two Cox proportional hazards models:

Model 1: Including hormon, age, tsize, tgrade, posnodes, progrec, and estrec as independent variables.
Model 2: Including hormon, tsize, tgrade, posnodes, and progrec as independent variables (excluding age and estrec).
The pooled likelihood ratio test statistic is 0.875, and the associated p-value is 0.350. This p-value is greater than the typical significance level of 0.05, which indicates that there is not enough evidence to suggest that Model 1 (including the age and estrec variables) provides a significantly better fit to the data compared to Model 2 (without the age and estrec variables).

In other words, based on this likelihood ratio test, both the age and estrec variables do not contribute significantly to the model's fit, and Model 2 (without the age and estrec variables) is sufficient for explaining the relationships between the other independent variables and the survival time of breast cancer patients.

#Evaluating the proportionality assumption using Schoenfeld residuals or log-log survival plots, and address any violations accordingly (e.g., stratification, time-dependent covariates).
```{r}
#To evaluate the proportionality assumption using Schoenfeld residuals, you can perform a global test on each imputed dataset and then pool the test results.

#To evaluate the proportionality assumption using Schoenfeld residuals for the cox_model_list2, you can use the cox.zph() function 
# Create a function to extract the Schoenfeld residuals from a Cox model
get_schoenfeld_res <- function(cox_model) {
  schoenfeld_res <- cox.zph(cox_model)
  schoenfeld_res_df <- data.frame(schoenfeld_res$z, schoenfeld_res$y)
  colnames(schoenfeld_res_df) <- c("Schoenfeld_Residual", "Time")
  return(schoenfeld_res_df)
}
cox_model_schoenfeld_list <- lapply(cox_model_list2, function(cox_model) {
  return(cox.zph(cox_model))
})
cox_model_schoenfeld_list
```

The Schoenfeld residuals test is used to test the proportional hazards assumption in a Cox proportional hazards model. The null hypothesis is that the covariates in the model do not violate the proportional hazards assumption.

The output shows the results of the test for each covariate in the model and for the global proportional hazards assumption.

In this case, the p-value for the global test is 0.0294, which is below the typical significance level of 0.05, indicating that there is evidence to suggest that the proportional hazards assumption has been violated.

To further investigate which covariates are violating the assumption, we can look at the individual tests. The covariates "tsize" and "tgrade" have p-values of 0.0408 and 0.0054 respectively, which are both below the significance level of 0.05, indicating that they violate the proportional hazards assumption. The remaining covariates ("hormon", "posnodes", and "progrec") do not violate the assumption, as their p-values are above the significance level.

In conclusion, the Cox proportional hazards model with covariates "tsize" and "tgrade" violates the proportional hazards assumption. This means that the effect of these covariates on the hazard rate may change over time, which can have important implications for the interpretation of the results. It may be necessary to consider alternative models, such as stratified Cox models or time-dependent Cox models, to address this violation.

```{r}
# Fit the Cox model on each imputed dataset and store the results in a list.
cox_model_list_strat <- lapply(imputed_bcs, function(x) {
  coxph(Surv(rectime, censrec) ~ hormon + strata(tsize) + strata(tgrade) + posnodes + progrec, data = imputed_bcs)
})

pooled_cox_model_strat <- pool(cox_model_list_strat)
summary(pooled_cox_model_strat)
```


The result shows the summary of the pooled Cox proportional hazards regression model that was fit on each imputed dataset. The model includes the variables hormon, posnodes, and progrec, as well as stratified variables for tsize and tgrade.

The estimates for hormon, posnodes, and progrec are -0.553, 0.064, and -0.002, respectively, indicating that hormon has a negative association with the outcome (recurrence-free survival), whereas posnodes and progrec have a positive and negative association with the outcome, respectively.

The p-values for all the variables are less than 0.05, indicating that they are statistically significant predictors of the outcome.

The use of stratified variables for tsize and tgrade indicates that the proportional hazards assumption was violated for these variables. By stratifying, we are allowing the baseline hazard function for each stratum to differ, which can account for the time-varying effect of tsize and tgrade on the outcome.
```{r}
estimates <- c(-0.553020766, 0.063729157, -0.001577577)
se_estimates <- c(0.1395428452, 0.0124773888, 0.0005300532)
alpha <- 0.05
z <- qnorm(1 - alpha / 2)
lower_limits <- estimates - z * se_estimates
upper_limits <- estimates + z * se_estimates
CI <- data.frame(
  Term = c("hormon", "posnodes", "progrec"),
  Estimate = estimates,
  SE = se_estimates,
  LowerCI = lower_limits,
  UpperCI = upper_limits
)

CI_table <- kable(CI, digits = 2, align = "c", col.names = c("Term", "Estimate", "SE", "LowerCI", "UpperCI"), caption = "Table-8: Summary Table")

print(CI_table)

```
```{r}
summary_df <- data.frame(
  Term = c("hormon", "posnodes", "progrec"),
  Estimate = round(c(-0.553020766, 0.063729157, -0.001577577), 3),
  Std.Error = round(c(0.1395428452, 0.0124773888, 0.0005300532), 3),
  Statistic = round(c(-3.963089, 5.107572, -2.976261), 3),
  df = round(c(301.9893, 301.9893, 301.9893), 3),
  p.value = round(c(9.239590e-05, 5.791714e-07, 3.153788e-03), 3)
)

summary_datatable <- datatable(summary_df, options = list(pageLength = 10, autoWidth = TRUE), caption = "Table")

print(summary_datatable)

estimates <- round(c(-0.553020766,  0.063729157, -0.001577577), 3)
se_estimates <- round(c(0.1395428452, 0.0124773888, 0.0005300532), 3)
alpha <- 0.05
z <- qnorm(1 - alpha / 2)
lower_limits <- estimates - z * se_estimates
upper_limits <- estimates + z * se_estimates

summary_df$LowerCI <- round(lower_limits, 3)
summary_df$UpperCI <- round(upper_limits, 3)

summary_datatable <- datatable(
  summary_df,
  options = list(pageLength = 10, autoWidth = TRUE),
  caption = "Table-7: Summary of Pooled Cox Model with Confidence Intervals"
)

print(summary_datatable)

```
The pooled Cox model shows that hormone treatment (hormon) has a significant negative association with the hazard rate (Estimate = -0.553, 95% CI: -0.827 to -0.280, p < 0.001), indicating that hormone treatment reduces the risk of the event of interest. The number of positive lymph nodes (posnodes) has a significant positive association with the hazard rate (Estimate = 0.064, 95% CI: 0.039 to 0.088, p < 0.001), suggesting that as the number of positive nodes increases, the risk of the event also increases. Progesterone receptor status (progrec) has a significant negative association with the hazard rate (Estimate = -0.0016, 95% CI: -0.0026 to -0.00054, p = 0.003), indicating that higher progesterone receptor levels are associated with a lower risk of the event.
```{r}
#To evaluate the proportionality assumption using Schoenfeld residuals, you can perform a global test on each imputed dataset and then pool the test results.

#To evaluate the proportionality assumption using Schoenfeld residuals for the cox_model_list2, you can use the cox.zph() function 
# Create a function to extract the Schoenfeld residuals from a Cox model
get_schoenfeld_res <- function(cox_model) {
  schoenfeld_res <- cox.zph(cox_model)
  schoenfeld_res_df <- data.frame(schoenfeld_res$z, schoenfeld_res$y)
  colnames(schoenfeld_res_df) <- c("Schoenfeld_Residual", "Time")
  return(schoenfeld_res_df)
}
cox_model_schoenfeld_list_strat <- lapply(cox_model_list_strat, function(cox_model) {
  return(cox.zph(cox_model))
})
cox_model_schoenfeld_list_strat
```
```{r}
# Create a data frame with variable names and p-values
Schoenfeldres_table <- data.frame(variable = c("hormon","posnodes", "progrec", "GLOBAL"), pvalue = c(0.63, 0.20, 0.47, 0.46), Chisq = c(0.23, 1.63, 0.53, 2.61))

# Print the p-value table using knitr::kable()
Schoenfeldres_table <- kable(Schoenfeldres_table, caption = "Table 5: Summary of the Schoenfeld residuals", align = "c")

Schoenfeldres_table
```
The output shows the results of the Schoenfeld residuals test for each covariate and the global test for the proportional hazards assumption. The null hypothesis for each test is that the covariate has a constant effect over time. If the p-value is less than 0.05, we reject the null hypothesis and conclude that the covariate violates the proportional hazards assumption.

In this case, all the p-values are greater than 0.05, which indicates that we fail to reject the null hypothesis for all covariates, and we can conclude that they satisfy the proportional hazards assumption. The global test also has a p-value of 0.46, indicating that there is no evidence of violation of the proportional hazards assumption for the entire model.

#Section - 4: Model Justification
The Cox proportional hazards model was chosen for this analysis due to several advantages it offers over other time-to-event models. These advantages include its semi-parametric nature, interpretability, and wide applicability in time-to-event analyses.

Semi-parametric nature: The Cox model is a semi-parametric model, meaning it does not require assumptions about the underlying distribution of survival times. This is an advantage over parametric survival models, which require a specific distribution (e.g., exponential, Weibull) to be chosen for the baseline hazard function. The semi-parametric nature of the Cox model allows for a more flexible modeling of the baseline hazard and enables the model to better capture complex relationships between the covariates and the survival times.
Interpretability: The Cox model provides hazard ratios for each covariate, which are easily interpretable and can be used to quantify the impact of each variable on the risk of the event of interest. Hazard ratios can be used to compare the relative risk of the event between different levels of a categorical variable or different values of a continuous variable. This makes it straightforward to communicate the results to a non-technical audience, such as clinicians or patients.
Wide applicability: The Cox model has been extensively used in time-to-event analyses across various fields, including medical research, epidemiology, and social sciences. Its wide applicability and robust performance make it a popular choice for analyzing time-to-event data.
The inclusion of the treatment variable "hormon" is explicitly requested in the task, indicating its importance in the study. Hormone therapy is a common treatment option for breast cancer, and its effect on the risk of cancer recurrence is of particular interest. In addition to "hormon", other covariates (age, menostatus, tsize, tgrade, posnodes, progrec, and estrec) are included in the analysis, as they are known to be clinically relevant and potential prognostic factors for breast cancer recurrence. Including these covariates allows for a more comprehensive understanding of the factors that influence the risk of recurrence and aids in the development of more effective treatment strategies.

While parametric survival models can be used for time-to-event analyses, they require a specific distribution to be chosen for the baseline hazard function, which may not always accurately capture the true relationship between the covariates and survival times. Furthermore, if the chosen distribution is incorrect, it can lead to biased estimates of the covariate effects. The Cox model was chosen over these alternatives due to its semi-parametric nature, allowing for more flexibility in modeling the baseline hazard and making fewer assumptions about the underlying survival distribution. This makes the Cox model a more robust choice for analyzing time-to-event data when the underlying distribution is unknown or complex.


#Section-5: Model Assessment
Assessing the model's goodness-of-fit and predictive performance using measures such as the concordance index (c-index), time-dependent ROC curves.
```{r}
# Calculate C-index for each imputed dataset
cindex <- sapply(cox_model_list_strat, function(x) {
  cindex <- 1 - (summary(x)$concordance / 2)
  return(cindex)
})
cindex

# Calculate AIC for each imputed dataset
aic <- sapply(cox_model_list_strat, AIC)
aic

# Calculate BIC for each imputed dataset
bic <- sapply(cox_model_list_strat, BIC)
bic
```
The code calculates the C-index, AIC, and BIC for each imputed dataset using a stratified Cox proportional hazards model with the covariates hormon, tsize, tgrade, posnodes, and progrec.

The cindex object shows the estimated C-index for each imputed dataset and its standard error. The C-index measures the concordance between the predicted and observed survival times, with values ranging from 0.5 (random prediction) to 1 (perfect prediction). In this case, the C-index values are all close to 0.66, suggesting that the model has moderate predictive accuracy.

The aic and bic objects show the AIC and BIC values for each imputed dataset, respectively. These are information criteria that balance the goodness of fit of the model and its complexity, with lower values indicating better model fit. In this case, the AIC and BIC values are all very close to each other, indicating that the model has similar fit across the imputed datasets.

Overall, these results suggest that the Cox proportional hazards model with the specified covariates has moderate predictive accuracy and fits the data well, with similar performance across multiple imputed datasets.
```{r}
# Fit Cox proportional hazards model to the complete dataset
cox_model_complete <- with(imputed_bcs, coxph(Surv(rectime, censrec) ~ hormon + strata(tsize) + strata(tgrade) + posnodes + progrec))

# Calculate C-index for the complete dataset
cox_model_complete_summary <- summary(cox_model_complete)
c_index <- cox_model_complete_summary$concordance
c_index

c_index_table <- data.frame(C_Index = c_index)

# Print the C-index table using knitr::kable()
c_index_table <- kable(c_index_table, caption = "Table: C-index for the Cox Proportional Hazards Model")

```

The code fits a Cox proportional hazards model to the complete imputed dataset using the covariates hormon, tsize, tgrade, posnodes, and progrec. The model is then used to calculate the C-index using the summary() function and extracting the concordance value.

The c_index object shows that the estimated C-index for the complete dataset is 0.674, with a standard error of 0.022. The C-index measures the concordance between the predicted and observed survival times, with values ranging from 0.5 (random prediction) to 1 (perfect prediction). In this case, the C-index value suggests that the model has moderate to good predictive accuracy for the complete dataset.

Note that the interpretation of the C-index depends on the context of the study and the clinical question being addressed. A C-index of 0.674 may be considered high or low depending on the specific application and the expected level of predictive accuracy. It is therefore important to interpret the C-index in light of the study design, patient population, and clinical context.

# Compute the time-dependent ROC curve and AUC
```{r}
#Time-dependent ROC curves: Time-dependent ROC curves are an extension of the traditional ROC curves for censored survival data. They can be used to assess the discriminative ability of the model at different time points. The area under the time-dependent ROC curve (AUC) can be used as a summary measure of the model's predictive performance. A higher AUC indicates better discrimination between subjects with and without the event of interest. In R, you can use the timeROC package to compute time-dependent ROC curves:

# Install and load the timeROC package

library(timeROC)

# Compute the time-dependent ROC curve and AUC
predicted_risk <- predict(cox_model_complete, type = "lp", newdata = imputed_bcs)
time_point <- 365 # Time point of interest (e.g., 1 year)
event_time <- imputed_bcs$rectime
event_status <- imputed_bcs$censrec

time_roc <- timeROC(event_time, event_status, marker = predicted_risk, cause = 1, times = time_point)
auc <- time_roc$AUC[1]
time_roc
```
```{r}
# Create a data frame with the output values
time_roc_output <- data.frame(
  Time = c("t=0", "t=365"),
  Cases = c(0, 67),
  Survivors = c(686, 588),
  Censored = c(0, 31),
  AUC = c(NA, 69.07)
)

# Print the output table using knitr::kable()
time_roc <- kable(time_roc_output, caption = "Table: Time-dependent ROC Curve Estimated Using IPCW (n=686, without competing risks)", align = "c")
time_roc
```



#Section-6: Reporting results

In this analysis, missing data was handled using multiple imputation, which is an approach that replaces each missing value with a set of plausible values to create multiple complete datasets. These datasets are then analyzed separately, and the results are combined to provide a single set of estimates and confidence intervals. Multiple imputation has the advantage of taking into account the uncertainty associated with the imputed values, leading to more accurate standard errors and confidence intervals compared to single imputation methods.

Although multiple imputation is a well-established method for handling missing data, there are some limitations to consider:

Assumptions: Multiple imputation assumes that the data are missing at random (MAR), meaning that the probability of a value being missing depends only on the observed data and not on the missing data itself. If the data are not MAR, the imputed values may be biased, and the resulting estimates may be inaccurate.
Model selection: The choice of a Cox proportional hazards model with time-dependent variables was made to account for the potential violation of the proportional hazards assumption. However, the selection of other models (e.g., parametric survival models) could potentially lead to different results. It is crucial to assess the goodness-of-fit and predictive performance of the chosen model to ensure its appropriateness for the data.
Potential biases: Despite the use of multiple imputation and time-dependent variables, biases can still be present in the analysis due to unmeasured confounding factors or incorrect model specifications. Additionally, if the imputation model does not accurately reflect the relationships among the variables, the imputed values may be biased.
Data quality issues: The quality of the data used in the analysis can affect the accuracy of the estimates. Errors in the data, such as misclassification or measurement errors, can lead to biased results.
In summary, while the use of multiple imputation and time-dependent variables helps address some of the limitations in the analysis, it is essential to recognize that potential biases and data quality issues can still impact the results. Careful consideration of the model assumptions, goodness-of-fit, and predictive performance, along with sensitivity analyses, can help assess the robustness of the findings.
The code calculates the time-dependent ROC curve and area under the curve (AUC) for a Cox proportional hazards model fitted to the complete imputed dataset using the covariates hormon, tsize, tgrade, posnodes, and progrec.

The predict() function is used to obtain the predicted risk scores for each observation in the imputed dataset. The type = "lp" argument specifies that the linear predictor (i.e., the log hazard ratio) should be returned.

The time_point object is set to 365 days, which represents the time point of interest for the ROC curve (i.e., 1 year). The event_time and event_status objects contain the survival time and censoring status for each observation, respectively.

The timeROC() function is then used to compute the time-dependent ROC curve, which estimates the sensitivity and specificity of the predicted risk scores at the specified time point. The cause = 1 argument specifies that the ROC curve should be based on the risk of experiencing the first event (i.e., breast cancer recurrence), rather than the risk of experiencing any event. The times argument specifies the time points at which the ROC curve should be calculated.

The time_roc object shows the results of the time-dependent ROC analysis. The first row of the table shows that there were no cases of breast cancer recurrence at time t=0, and that all 686 patients were still alive. The second row shows that at time t=365, there were 67 cases of breast cancer recurrence, 588 patients were still alive, and 31 patients were censored (i.e., lost to follow-up or withdrew from the study). The AUC of the ROC curve at time t=365 is 69.07%, indicating that the model has moderate predictive accuracy at this time point.

Note that the interpretation of the AUC depends on the specific application and the clinical question being addressed. An AUC of 69.07% may be considered high or low depending on the context of the study and the expected level of predictive accuracy. It is therefore important to interpret the AUC in light of the study design, patient population, and clinical context.


```{r}
#to examine the estimated regression coefficients and their statistical significance
summary(cox_model_complete)
```
The summary() function is used to obtain a summary of the Cox proportional hazards model fitted to the complete imputed dataset using the covariates hormon, tsize, tgrade, posnodes, and progrec.

The output shows the estimated coefficients (coef), exponentiated coefficients (exp(coef)), standard errors of the coefficients (se(coef)), z-scores (z), and p-values (Pr(>|z|)) for each covariate in the model. The ***, **, and * symbols indicate statistical significance at the 0.001, 0.01, and 0.05 levels, respectively.

The exp(coef) values represent the hazard ratio (HR) for each covariate, which indicates the change in the hazard of breast cancer recurrence associated with a one-unit increase in the corresponding predictor, holding all other predictors constant. For example, the HR for hormon is 0.5752, indicating that patients with a positive hormone receptor status have a 42.5% lower hazard of breast cancer recurrence compared to patients with a negative hormone receptor status, holding all other predictors constant.

The lower .95 and upper .95 values represent the 95% confidence intervals (CI) for the HR estimates.

The output also shows the concordance index (Concordance), which measures the predictive accuracy of the model, with values ranging from 0.5 (random prediction) to 1 (perfect prediction). In this case, the estimated concordance index is 0.674, with a standard error of 0.022. This suggests that the model has moderate predictive accuracy for breast cancer recurrence.

The likelihood ratio test (Likelihood ratio test), Wald test (Wald test), and score (logrank) test (Score (logrank) test) are statistical tests of the null hypothesis that all the regression coefficients are equal to zero. The small p-values (i.e., p=5e-13, p=3e-11, and p=1e-12) indicate strong evidence against the null hypothesis, suggesting that at least one of the covariates is associated with the hazard of breast cancer recurrence.


#Calculate hazard ratios (HRs) and their 95% confidence intervals to quantify the effect of each predictor variable on the hazard rate.

```{r}
# Extract hazard ratios (HRs) and 95% confidence intervals from the summary
cox_summary <- summary(cox_model_complete)
hr_table <- data.frame(
  Variable = rownames(cox_summary$conf.int),
  HazardRatio = round(cox_summary$conf.int[, "exp(coef)"], 3),
  LowerCI = round(cox_summary$conf.int[, "lower .95"], 3),
  UpperCI = round(cox_summary$conf.int[, "upper .95"], 3)
)

# Print the HR table
#print(hr_table)

hr_table <- kable(hr_table, caption = "Table-8: Hazard Ratios and 95% Confidence Intervals")
hr_table
```

The code extracts the hazard ratios (HRs) and 95% confidence intervals (CI) for each predictor variable in the Cox proportional hazards model fitted to the complete imputed dataset. The data.frame() function is used to create a new data frame hr_table, which includes the predictor variable names (Variable), the corresponding HR estimates (HazardRatio), and their respective lower (Lower95CI) and upper (Upper95CI) 95% CIs.

The print() function is then used to display the hr_table in the console. The table shows that the HR for hormon is 0.575 with a 95% CI of 0.438 to 0.756, indicating that patients with a positive hormone receptor status have a significantly lower hazard of breast cancer recurrence compared to patients with a negative hormone receptor status, after adjusting for the other predictors in the model.

The HR for posnodes is 1.066 with a 95% CI of 1.040 to 1.092, indicating that each additional positive axillary lymph node is associated with a 6.6% increase in the hazard of breast cancer recurrence, holding all other predictors constant.

The HR for progrec is 0.998 with a 95% CI of 0.997 to 0.999, indicating that each one-unit increase in the proportion of the genome that is involved in breast cancer progression is associated with a 0.2% decrease in the hazard of breast cancer recurrence, holding all other predictors constant. However, the p-value of 0.00292 suggests that the effect size of progrec is statistically significant but possibly clinically small.


#Section-6: Reporting results

In this analysis, missing data was handled using multiple imputation, which is an approach that replaces each missing value with a set of plausible values to create multiple complete datasets. These datasets are then analyzed separately, and the results are combined to provide a single set of estimates and confidence intervals. Multiple imputation has the advantage of taking into account the uncertainty associated with the imputed values, leading to more accurate standard errors and confidence intervals compared to single imputation methods.

Although multiple imputation is a well-established method for handling missing data, there are some limitations to consider:

Assumptions: Multiple imputation assumes that the data are missing at random (MAR), meaning that the probability of a value being missing depends only on the observed data and not on the missing data itself. If the data are not MAR, the imputed values may be biased, and the resulting estimates may be inaccurate.
Model selection: The choice of a Cox proportional hazards model with stratified variables was made to account for the potential violation of the proportional hazards assumption. However, the selection of other models (e.g., parametric survival models) could potentially lead to different results. It is crucial to assess the goodness-of-fit and predictive performance of the chosen model to ensure its appropriateness for the data.
Potential biases: Despite the use of multiple imputation and stratified variables, biases can still be present in the analysis due to unmeasured confounding factors or incorrect model specifications. Additionally, if the imputation model does not accurately reflect the relationships among the variables, the imputed values may be biased.
Data quality issues: The quality of the data used in the analysis can affect the accuracy of the estimates. Errors in the data, such as misclassification or measurement errors, can lead to biased results.
In summary, while the use of multiple imputation and stratified helps address some of the limitations in the analysis, it is essential to recognize that potential biases and data quality issues can still impact the results. Careful consideration of the model assumptions, goodness-of-fit, and predictive performance, along with sensitivity analyses, can help assess the robustness of the findings.
















